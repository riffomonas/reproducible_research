---
layout: presentation
title: Introduction to Reproducible Research
permalink: /tutorials/introduction/
---
class: middle center

# {{ page. title }}

---

## Learning goals

* **Primary:** Understand that reproducible research refers to the ability of
  another researcher to use your methods to reproduce your results
--

* **Secondary:**
  * Be able to articulate the causes and possible solutions for the lack of
  reproducibility in microbiome research
  * Appreciate that an inability to reproduce another researcher's results
  limits the ability to build off of that work

???

---

## Learning outcomes

* Articulate the importance of making raw data and detailed methods accessible
* Identify various technologies as solutions to practices that limit
  reproducibility

???

---

background-image: url(/assets/images/jir.jpg)
background-size: contain
background-position: 50% 50%

???

What are the consequences of the public not trusting science?

???

---

## Definitions

* **Reproducibility:** "Ability to recompute data analytic results given an observed data set and knowledge of the data analysis pipeline."
* **Replicability:** "The chance that an independent experiment targeting the same scientific question will produce a consistent result."

.footnote[[Leek & Peng. 2015 *PNAS*](http://www.pnas.org/cgi/doi/10.1073/pnas.1421412111)]

???

--
## .alert.center[Beware! Depending on who is talking, the definitions may be flipped]

---

## Pop quiz: Reproducibility or Replicability?

* A new person joins the lab and tries to repeat a previous lab member's experiments
???
reproducibility
--

* You download data from another lab, following their methods, you try to regenerate their results
???
replicability
--

* You start your first faculty position and rerun the mouse model that you ran as a postdoc
???
replicability
--

* Someone performs your study using a cohort of subjects in Korea
???
replicability
--

* A colleague asks for your raw data and any scripts you may have to repeat your earlier analysis
???
reproducibility

---

## What are the threats to *replicability*?

--

.left-column[
* Not a real effect
* Poor experimental design
* Contaminated/mistaken reagents
* Confounding variables
* Sex
* Age
]

.right-column[
* Mouse genotype
* Differences in reagents or populations
* Sloppiness
* Selection and experimental bias
* Fraud/Scientific misconduct
]
---

## What are the threats to *reproducibility*?

--

.left-column[
* Data are not publicly available
* Incomplete methods section
* Operating systems
* Evolution of software/databases
]

.right-column[
* Availability of software
* "Custom XXXXX scripts"
* URL rot
* Email rot
* This stuff is *really* hard!
]

---

background-image: url(/assets/images/asm-reproducibility.jpg)
background-size: contain
background-position: 50% 50%

.footnote[[Casadevall et al. 2016 *mBio*](http://mbio.asm.org/content/7/4/e01256-16.abstract)]

--

class: middle
.blur-background[
	.center[![ASM Colloqium Blurb](/assets/images/asm-reproducibility-blurb.png)]
]

???

* Is this reproducibility, replicability, or neither?
* What would you have said to the colloquium participants?

---
class: center middle

## Is research that is reproducible and/or replicable necessarily correct?

---

## Case study


Your lab publishes a paper and gets inundated by emails asking about the nitty gritty of the methods. The trainee that did the study has gone on to a new job.

???

* Have you ever requested information from an author? What happens?
* Have you ever been pinged for information? What happens?
* What can you do to be proactive to avoid these cases?
* How useful are laboratory notebooks?
* How long are you responsible for maintaining these records?
* How long can you reasonably expect someone to be helpful?

---

## The Reproducibility Crisis: Bayer

> An unspoken rule among early-stage venture capital firms that “at least 50% of published studies, even those in top-tier academic journals, can't be repeated with the same conclusions by an industrial lab"

.footnote[[Prinz et al. 2011. *Nature Reviews Drug Discovery*]( http://www.nature.com/nrd/journal/v10/n9/full/nrd3439-c1.html)]

--

![Prinz et al. figure](/assets/images/prinz-replicability.png)


???

Survey based analysis at Bayer based on their "eaarly (target identification and validation) in-house projects in our strategic research fields of oncology, women's health and cardiovascular diseases that were performed over the past 4 years"



---

## The Reproducibility Crisis: Amgen

![Begley & Ellis table](/assets/images/begley-replicability.png)

.footnote[[Begley & Ellis 2012. *Nature*]( http://www.nature.com/nature/journal/v483/n7391/full/483531a.html)]

--
> Cancer researchers must be more rigorous in their approach to preclinical studies. Given the inherent difficulties of mimicking the human micro-environment in preclinical research, reviewers and editors should demand greater thoroughness


???

Some non-reproducible preclinical papers had spawned an entire field, with hundreds of secondary publications that expanded on elements of the original observation, but did not actually seek to confirm or falsify its fundamental basis. More troubling, some of the research has triggered a series of clinical studies — suggesting that many patients had subjected themselves to a trial of a regimen or agent that probably wouldn't work.

---

class: center middle
# .alert[Inconvenient Truth: Neither study did anything to demonstrate that their work could be reproduced]

---

## NIH's Response: Technical Factors

* Publications rarely report basic elements of experimental design
	* Blinding, Randomization, Replication
	* Sample-size calculation
	* Effect of sex differences
	* Underlying data rarely made publicly available
* Restrictions on lengths of methods sections
* Assume reader is at an idealized level of expertise


.footnote[[Collins & Tabak 2014. *Nature*]( http://www.nature.com/news/policy-nih-plans-to-enhance-reproducibility-1.14586)]


???
Important to note that Collins & Tabak did not think this was a matter of fraud:

"Let's be clear: with rare exceptions, we have no evidence to suggest that irreproducibility is caused by scientific misconduct. In 2011, the Office of Research Integrity of the US Department of Health and Human Services pursued only 12 such cases"

The development of instructional materials for this workshop was funded through an R25 mechanism that was a response to these issues

---

## NIH's Response: Social Factors

* Failure to publish negative effects (i.e. file drawer problem)
* "Some scientists reputedly use a 'secret sauce' to make their experiments work"
* Perverse incentives to publish and hype striking results
* [Impact Factor Mania](http://mbio.asm.org/content/5/2/e00064-14.full)

.footnote[[Collins & Tabak 2014. *Nature*]( http://www.nature.com/news/policy-nih-plans-to-enhance-reproducibility-1.14586)]

???

---

background-image: url(/assets/images/nih-grant-guideline.jpg)
background-size: contain
background-position: 50% 50%

???

There is a big push by NIH to improve the reproducibility and replicability of ongoing research. Much of these efforts have focused on what we are calling replicability.

---

## Ravel & Wommack editorial in *Microbiome*

![Ravel & Wommack editorial screen shot](/assets/images/all-hail-reproducibility.png)

.footnote[[Ravel & Wommack 2014. *Microbiome*]( https://microbiomejournal.biomedcentral.com/articles/10.1186/2049-2618-2-8)]

???

* Initial thoughts?
* "... it is no mistake that the best documented code turns out to be more frequently used by microbiome researchers"
* Identify 5 different technologies or platforms that hte authors point to for improving reproducibility of microbiome research
	* Data accessibility - SRA, dbGaP, figshare
	* Metadata - MIMARKS
	* Code/workflow - iPython notebooks/knitr
	* Version control - git and GitHub

---

## Threats to reproducibility & replicability of microbiome research

--

.left-column[
* Lack of standard methods
* Accessibility of data
* Different populations
* Complex and lengthy data analysis
]

.right-column[
* Variation in mouse colonies
* Contaminants in low biomass samples
* Sampling artifacts
]

---

## Case study

Consider the [GitHub repository](https://github.com/jfmeadow/Meadow_etal_Surfaces) that accompanied the paper by [Meadows et al.](http://microbiomejournal.biomedcentral.com/articles/10.1186/2049-2618-2-7) described by Ravel & Wommack

* How accessible is the code?
* What do you need to know to make sense of the repository?
* Is it well documented?
* How well organized is the repository?
* How long did it take you to find the code for the figures?

???

Comments:
* Data deposited in figshare rather than SRA (not good)
* Not very well organized, but it's a small project
* The Rmd provides narrative to explain what's happening
* The figure code is in LillisSurfaces.Rmd and it is rendered in LillisSurfaces.md
---

## Critique a recent microbiome paper

* Checklist
  * How difficult it be to regenerate a P-value or a figure?
	* Where are the raw data?
	* Is the code available?
	* How long is the Methods section?

* Some possible examples from the Schloss Lab...
  * [Sze & Schloss. 2016 *mBio*](http://mbio.asm.org/content/7/4/e01018-16)
  * [Baxter et al. 2015 *Appl Env Microbiol*](http://aem.asm.org/content/81/1/396)
  * [Zackular et al. 2013 *mBio*](http://mbio.asm.org/content/4/6/e00692-13.long)

---

## Go explore: Look in the mirror...

* Perform an audit of your research group's most recent publications and score them for their reproducibility using a checklist
* What would be the most important thing to improve for your group's next paper?

---

## Why is reproducibility/replicability important?

--

* To make sure that the results are correct and/or generalizable
--

* So that others can build off of earlier work
--

* To enable others to repurpose materials and methods

---

## Preventative medicine

* Too much emphasis on "gotcha science"
* Research done in a manner to maximize reproducibility...
	* makes life easier for you in the long run
	* instills more confidence by others
	* is easier for others to build from

.footnote[Leek & Peng. www.pnas.org/cgi/doi/10.1073/pnas.1421412111]

---

## Who must be able to reproduce your research?

--

.middle[.center[![You!](/assets/images/you.gif)]]

--

.middle[.center[![Your PI](/assets/images/boss.gif)]]

---

## First steps to reproducibility

* ORCID

* Post data behind your figures

* Making your code publicly available

---

## ORCID

* Why:
	* Will your current email address be any good in 10 years?
	* Ties in other services (e.g. ImpactStory, LinkedIn, ResearchGate)
	* It's free!
* How:
  * https://orcid.org

---

class: center middle

![ORCID screen shot](/assets/images/orcid.png)

---

## Post data behind your figures


* What's wrong with posting data on a private server?

--

* Sequence data and metadata must be posted to SRA

--

* Other data should be posted to stable web server (e.g. FigShare)
  * Provides DOIs for each set of data
  * Prohibits user from deleting data
  * Is free (within limits)

--

* Can you find the [FigShare accession](https://figshare.com/articles/Lillis_Classroom_Surfaces/687155) from Meadows et al?

---

## Making your code publicly available

* Make a [GitHub](http://www.github.com) account and log in

.middle.center[![GitHub sign up page](/assets/images/github-signup.png)]

???

You might take a minute and think of a good GitHub handle for your account. Many people bemoan the fact that they have separate GitHub, email, and Twitter handles. The handles don't work across platforms, it is often easier for you - and your friends - to keep track of you if you are consistent.

---

## Making your code publicly available

* Create a new repository

.middle.center[![Your new home in GitHub](/assets/images/github-user-home.png)]

???

When you log in to GitHub you'll see a "+" at the top right corner of the window, click on this, and then select "New Repository"

---

## Making your code publicly available

.middle.center[![GitHub sign up page](/assets/images/github-create-new-repository.png)]

???

Here we'll create a new repository - possibly your first - how exciting!
* Insert a name for your repository. Try to make it meaningful. For our papers we give them names that start FirstAuthorLastName_OneWordDescriptionOfPaper_Journal_Year. For example, Sze_Obesity_mBio_2016 was a paper published in mBio during 2016 that Marc Sze wrote on obesity and the microbiome (this can be changed later)
* Add a one line description of your project (this can be changed later)
* Select "Public". GitHub gives out repositories for free if they are public. You can email them to set up an academic account, which will give you unlimited Private accounts. Be sure to make them Public before you submit your manuscripts
* Check the box to "Initialize this repository with a README"
* Select the "MIT License" in the right hand side scroller
* Click "Create repository"
---

## Making your code publicly available

.middle.center[![GitHub new repository](/assets/images/github-new-repository.png)]

???

Well done! You have your first repository created. You can actually do quite a bit without knowing
any git. Let's try out some things...

---

## Making your code publicly available

.middle.center[![GitHub new repository](/assets/images/github-edit-readme.png)]

???

* Click on the blue `README.md` link in the middle of your repository screen and then click on the pencil in the upper right corner of the box.
* Toggle between the "Edit file" and "Preview changes" tab - Change the '`# rr_practice`' to '`# README`'

---

## Making your code publicly available

* A file ending in `md` indicates that it is a file in "markdown" format
* This is a text file (*not a Word file*)
* There are simple "markups" that you can do to add formatting to the text

---
## Making your code publicly available

* You can explore [GitHub-flavored markdown](https://guides.github.com/features/mastering-markdown/) further
* Make the following changes and toggle back and forth from the preview...
  * `#` to `##` or `###`
  * `efforts` to `*efforts*`, `**efforts**`, `***efforts***`, or `~~efforts~~`
  * Add a bulleted list

---

## Exercise

* Edit the README.md file
	* Give the file a more descriptive title using a `#` header
	* Write today's date on a separate line
	* Write instructions for how to fold a paper airplane
* Look at the bottom of the README.md page
  * In the narrow box below "Commit changes" enter a brief description of what you changed in the file
  * In the larger box, write a more detailed description
  * Press the green "Commit changes" box

---

## Exercise

* Send a link to your repository to a neighbor and ask them to follow the directions.
* Revise your instructions based on your neighbor's success or failure.
* "Commit" the change


* E-mail me a link to your repository

---
layout: presentation
title: Working on a High Performance Computer (HPC)
permalink: /hpc/
---

class: middle center

# {{ page.title }}

---

## This is an aside

* Whether you use an HPC is not critical to whether your work is reproducible
* The material in this session is presented
  * So that people following along can reproduce what I am doing
  * Introduce and justify HPCs over personal computers
* There are some fringe benefits of using an HPC that can benefit reproducibility

---

## Learning goals

* Identify the practical and financial benefits of using high performance computers over a local computer
* Identify your options for accessing a HPC
* Use a scheduler on your local HPC
* Use the interactive mode with your local computer cluster
* Run jobs with `tmux`
* Access HPC resources on Amazon Web Services (AWS)

---


class:middle

## Most Frequently Asked Question...

--

## .alert.center[What type of computer should I get?]

???

I really hate this question because I don't want to spend other people's money!
When you're picking out a computer there are a few things to consider

---

## Ask yourself...

.footnote[[Melba Roy Mouton](https://en.wikipedia.org/wiki/Melba_Roy_Mouton), an early NASA "Computer"]

.left-column[
* What am I going to use it for?
*	What is my budget?
* How much RAM do I need?
* How much CPU speed?
* How many CPUs?
* How much space do I need?
* What operating system do I want?
* What does my lab use?
]


.center.right-column[
![:scale Melba Roy, 80%]({{ site.baseurl }}/assets/images/melba_roy.jpg)
]


---

## Problem with modern computers

* They get old. Quick
* They sit idle. A lot
* They can be expensive
* They can be ridiculously cheap
* Hard to predict what you are going to use them for

---

## Quick comparison

* MacBook Pro
  * 15 in, 2.9GHz, 16GB RAM, 512GB SSD: <span style="color:red">**$2,800**</span>
  * 13 in, 2.3GHz, 8GB RAM, 256GB SSD: <span style="color:red">**$1,500**</span>

* Dell XPS (Windows)
  * 15 in, 2.4GHz, 16GB RAM, 512GB SSD: <span style="color:red">**$2,000**</span>
  * 13 in, 1.9GHz, 8GB RAM, 256GB SSD: <span style="color:red">**$1,050**</span>

* System 76 (Linux)
  * 15 in, 3.5GHz, 16GB RAM, 512GB SSD: <span style="color:red">**$1,200**</span>
  * 14 in, 2.4GHz, 16GB RAM, 256GB SSD: <span style="color:red">**$828**</span>

.footnote[For comparison purposes only]

???

Note that you can buy laptops even cheaper than these, but these are provided as a reference

---

## HPC pricing

* [Amazon Web Services](https://aws.amazon.com/ec2/pricing/on-demand/)
  * 4 CPU, 16GB RAM (on demand) ~ $0.20/hour
  * 8 CPU, 32GB RAM (on demand) ~ $0.40/hour
  * 64 CPU, 256GB RAM (on demand) ~ $3.20/hour
* University of Michigan "[FLUX](http://arc-ts.umich.edu/rates/)"
  * $16.94 per core per month (on demand; 4GB RAM per core)
  * $13.30 per core per month (whole month; 25GB RAM per core)
* Other public and commercial computer clusters are available

???

* Prices don't include cost of storage, which is generally pretty cheap
* AWS also provides additional educational discounts
* UM heavily subsidizes cost of HPC - about half the cost of AWS

---

## Benefits of HPC

* Hardware constantly updated at no cost to you
* Cheap! With AWS $1,000 would last 104 days with 100% usage (unlikely)
* [Flexible](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-resize.html)!
  * May only need 8 CPU/32 GB RAM for short period
  * Downstream analyis with R could possibly be done on free instances
* Reinforces good reproducible research practices

--

<br>

.alert.center[With availability of HPC, you are better off thinking of your laptop as a terminal rather than as a workhorse]

---

## Drawbacks of HPC

* Learning curve
* Learn command line
* It feels weird at first

???

You could buy a lot of Dr. Pepper and ice cream with the money you save, which would help me get over these drawbacks

---

## Your local HPC

![Flux configuration]({{ site.baseurl }}/assets/images/flux_configuration.jpg)

???

* You log into the head node from your computer.
* You will get yelled at if you run anything significant on the head node. Some systems will automatically boot you from the system if you run things on the head node
* You cannot directly log into the compute nodes
* Must submit a "job" to run your processes on one of the compute node
* Can submit multiple jobs at the same time using a scheduler

---

class:middle

## Disclaimer...

... your local HPC should hopefully have their own instructional materials to get you going. This is only to give you a rough look at what's going on

---

## Getting to your HPC

* Need to get information from your systems administrators
* Will likely use:
  * [`ssh`](https://www.ssh.com/ssh/): Mac OS X or Linux
  * [`PuTTY`](https://www.chiark.greenend.org.uk/~sgtatham/putty/): Windows
* May need to navigate things like:
  * VPN
  * Two-factor authentication

---

## Install software

* Can generally install software in your own storage to run on the HPC
* Most HPCs also have a system where you can "load" modules to make common software available

```
$ module avail                 # list software that is available to load
$ module list                  # list software that you have already loaded
$ module load [modulename]	# load [modulename]
$ module unload [modulename]  # unload [modulename]
$ module save                  # save list of modules to load for each session
```

--
Here's what I have loaded:

```
$ module list

Currently Loaded Modules:
  1) gcc/4.9.3      3) samtools/1.2              5) r-biomed-libs/3.3.2
  2) boost/1.61.0   4) python-anaconda3/latest   6) R/3.4.1

```

Really only need gcc, boost, and R for these tutorials

---

## Scheduler

* Your HPC will have software it uses to manage the jobs of you and everyone else
* Mine uses Torque Portable Batch System (PBS)
* PBS queues, starts, controls, and stops jobs
* There are many ways to use PBS, I'll show you two: interactive and batch mode

---

## Batch mode

```bash
#!/bin/sh
#PBS -l nodes=1:ppn=12
#PBS -l mem=10gb
#PBS -l walltime=500:00:00
#PBS -j oe
#PBS -m abe
#PBS -V
#PBS -M your_email@your_institution.edu
#PBS -A example_fluxod
#PBS -q fluxod
#PBS -l qos=flux


echo "ncpus-2.pbs"
cat $PBS_NODEFILE
qstat -f $PBS_JOBID

cd $PBS_O_WORKDIR

NCPUS=`wc -l $PBS_NODEFILE | awk '{print $1}'`

# Put your bash code below here

# Put your bash code above here

echo "qsub working directory absolute is"
echo $PBS_O_WORKDIR
exit
```

Save as `my_job.qsub`

???

* ppn is the number of processors/cores you want to run per node (customize to your project/resources)
* mem is the amount of memory you want to request (if this is above the available memory, the job will never launch)
* walltime is in hours:minutes:seconds (your hpc may have limits)
* -M put your email to get emails regarding status of your job
* -A indicates your account (may not be required by your HPC)
* -q is the queue that you want to be in (unless you're at UMich, it won't be fluxod)
* qos is specific to your HPC
---

## Run your bash code by doing this...

<br>

```bash
$ qsub my_job.qsub
```

* Once you submit the job, you can then log out and go away
* It may take some time for the scheduler to launch your job. If it is taking more than 30 minutes, contact your SysAdmin and ask what is going wrong
* When your job completes, you'll get an email
* This can be hard if using batch scripts is foreign to you

---

## Interactive mode

* We might want to run something interactively
* Can do what we had previously like this:

```bash
$ qsub -I -V -A example_flux -q flux -l nodes=1:ppn=12,pmem=10gb,walltime=500:00:00,qos=flux
```

* Typing all of that can get tedious and you may forget what options to include

---

## Interactive mode with a file

```bash
#!/bin/sh
#PBS -l nodes=1:ppn=12
#PBS -l mem=10gb
#PBS -l walltime=500:00:00
#PBS -j oe
#PBS -m abe
#PBS -V
#PBS -A example_fluxod
#PBS -q fluxod
#PBS -l qos=flux


echo "ncpus-2.pbs"
cat $PBS_NODEFILE
qstat -f $PBS_JOBID

cd $PBS_O_WORKDIR

NCPUS=`wc -l $PBS_NODEFILE | awk '{print $1}'`
```

* Save this as `interactive.qsub`
* Run as:

```bash
$ qsub -I interactive.qsub
```

* Then run your commands as you would normally

---

## But!

* You might have a job that needs to run for a long period of time
  * Power could go out
  * Internet might drop you
  * You might want to move computer
* Instead, run the interactive job in the background using the [`tmux`](https://gist.github.com/MohamedAlaa/2961058) program

```bash
$ tmux
$ qsub -I interactive.qsub
$ mothur
```

---

## `tmux`

* `tmux`: Start a session
* `Control-b d`: Detach from current session
* `tmux ls`: List existing tmux sessions
* `tmux a` or `tmux a #0`: Attach a specified session
* There are many other commands and features for use wiht `tmux`, but these will get you pretty far

--

<br>
.alert.center[Remember to use `tmux` before starting your interactive PBS session!]

---

## Other PBS tools to know

* `qstat -u your_username`: List out the jobs you have submitted and their status
* `qdel [job_id]`: Kill one of your jobs

---

## Amazon Web Services (AWS)

.left-column[
* Many "services"
  * Compute nodes
  * Long and short term Storage
* Widely used
  * Many commercial applications
  * Web hosting
  * Education applications
]
.right-column[

<br>
![AWS Services Webpage]({{ site.baseurl }}/assets/images/aws_splash.png)

]

---

## Amazon Elastic Compute Cloud (EC2)

* This is the service that we will primarily utilize for this series of tutorials
* Create virtual computing environments that are called "instances"
* Build upon existing instances called Amazon Machine Images (AMIs)
* "Elastic" comes from the ability to manipulate the hardware configuration of the instance you are using
* Can create your own AMI, which is preloaded with software and data and that you can share with others

---

## Do the [AWS Tutorial](https://aws.amazon.com/getting-started/tutorials/launch-a-virtual-machine/)

![AWS Launch a Linux Virtual Machine]({{ site.baseurl }}/assets/images/aws_tutorial.png)

???

Really important to go through this to demonstrate how to set up account and key pair

---

## Let's go...

.left-column[
* Go to https://aws.amazon.com
* Click "Sign In to the Console"
* Either Sign In using your existing Amazon account or create a new account
* Type "EC2" in the search window in the upper right corner of the screen
* Hit enter
]

.right-column[
![Services listing]({{ site.baseurl }}/assets/images/aws_services.png)
]

???

* Note that AWS periodically moves things around
* The details of these instructions and screen shots may change over time, but they should provide a good road map
---

## EC2

.left-column[
* At this point you will see a dashboard that tells you what resources you are using
* If you've never logged in before, you'll have a bunch of zeroes on this page
* In the upper right corner of the screen next to your name is the region that your instance will be living in. Make sure it is set to "N. Virginia"
* Click blue "Launch Instance" button
]

.right-column[
<br>
![EC2 dashboard]({{ site.baseurl }}/assets/images/aws_ec2_dashboard.png)
]

---

## Finding an AMI

.footnote[[Details of how riffomonas AMI was constructed](https://github.com/riffomonas/reproducible_research/blob/gh-pages/rr_notes_prep.md)]

.left-column[
* Along the left side click on the tab that says "Community AMIs"
* In the search bar that says "Search Community AMIs", type "riffomonas"
* Select the most recent version of the AMI (year-month format)
* Press "Select" button
]

.right-column[
<br>
![Selecting AMI Instance]({{ site.baseurl }}/assets/images/aws_ami_selection.png)
]


---

## Select instance type

<br>
.center[![:scale Selecting AMI Instance, 70%]({{ site.baseurl }}/assets/images/aws_instance_type.png)]

.footnote[[Numerous options available](https://aws.amazon.com/ec2/pricing/on-demand/)]
???

* You'll have to scroll down to find the m4.2xlarge instance type
* Press "Next: Configuration Instance Details"
* Press "Next: Add Storage"

---

## Add storage

<br>
.center[![:scale Set amount of storage, 70%]({{ site.baseurl }}/assets/images/aws_storage.png)]

???

* Change the amount of storage to 50
* Press blue "Review and Launch" button
* Press blue "Launch" button

---

## Security

.center[![:scale Set key-pair, 80%]({{ site.baseurl }}/assets/images/aws_key_pair.png)]

???

* Select the key-pair that you generated in the tutorial
* Check the box that you have access to the key-pair
* Select blue "Launch Instances" button

---
class:middle, center

![Instances are running]({{ site.baseurl }}/assets/images/aws_view_instances.png)

---
class:middle, center

![Instances dashboard]({{ site.baseurl }}/assets/images/aws_instances_dashboard.png)

---

## Connecting

```bash
$ ssh -i ~/.ssh/mothur.pem ubuntu@54.90.95.116
The authenticity of host '54.90.95.116 (54.90.95.116)' can't be established.
ECDSA key fingerprint is SHA256:wE5Nlhu+JLSYp7qWYjQKWwsVbc6Imd26fUN0htxEP+Q.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '54.90.95.116' (ECDSA) to the list of known hosts.
Welcome to Ubuntu 16.04.2 LTS (GNU/Linux 4.4.0-1016-aws x86_64)
```

* May get warnings about packages being out of date...

```bash
$ sudo apt upgrade
```

* May get a comment about needing to restart instance
  * Go back to instance dashboard"Action -> Instance State -> Reboot"

???
Note that the login will ask whether you want to continue connecting

---

## Now what?

* You're using your own computer that is hosted by AWS
* `tmux` and rock on!
* Moving data around...
  * Later we'll see how to get data into your instance using `wget` and `curl`
  * Can also use `sftp` to pull things down and put them up ~ same syntax as ssh
  * Perhaps easiest way is to use the [FileZilla](https://filezilla-project.org/download.php?type=client) client


???


---


## Setting up FileZilla

.left-column[
* FileZilla can be run on Windows, Mac OS X, and Linux
* Download and install the appropriate version of [FileZilla](https://filezilla-project.org/download.php?type=client) for your computer (You don't need the "Pro" version)
]

.right.right-column[

![:scale What a fresh install of FileZilla looks like, 90%]({{ site.baseurl }}/assets/images/filezilla_fresh.png)

]

---

class: middle, center

![:scale Click on SFTP and then Add key file...]({{ site.baseurl }}/assets/images/filezilla_sftp_settings.png)

---

class: middle, center

![:scale Add keypair file...]({{ site.baseurl }}/assets/images/filezilla_find_keypair.png)

???

* On a Mac, hold down CMD-Shift-. (dot) to see the hidden files

---

class: middle, center

![:scale keypair successfully loaded...]({{ site.baseurl }}/assets/images/filezilla_keypair_loaded.png)

---

class: middle, center

![:scale Need to connect to our server...]({{ site.baseurl }}/assets/images/filezilla_select_server.png)

---

class: middle


.center.left-column[
![:scale Need the DNS from AWS...]({{ site.baseurl }}/assets/images/filezilla_aws_dns.png)
]

.center.right-column[
![:scale Enter the information into Filezilla]({{ site.baseurl }}/assets/images/filezilla_aws_host_info.png)
]


---

class: middle, center

![:scale Approve the key connection...]({{ site.baseurl }}/assets/images/filezilla_approve_host_key.png)

---

class: middle, center

![:scale Connected]({{ site.baseurl }}/assets/images/filezilla_aws_connected.png)

???

We would like to get rid of those dot (hidden) files

---

class: middle, center

![:scale Filezilla -> View ]({{ site.baseurl }}/assets/images/filezilla_view.png)

---

class: middle, center

![:scale Create a filter ]({{ site.baseurl }}/assets/images/filezilla_filters.png)

---

class: middle, center

![:scale Create a filter ]({{ site.baseurl }}/assets/images/filezilla_create_filter.png)

---

class: middle, center

![:scale Create a filter ]({{ site.baseurl }}/assets/images/filezilla_filter_name.png)

---

class: middle, center

![:scale Create a filter ]({{ site.baseurl }}/assets/images/filezilla_program_filter.png)

---

class: middle, center

![:scale Create a filter ]({{ site.baseurl }}/assets/images/filezilla_apply_ok_filter.png)

---

class: middle, center

![:scale Create a filter ]({{ site.baseurl }}/assets/images/filezilla_filter_effect.png)

---

class: middle, center

![:scale Set double click behavior ]({{ site.baseurl }}/assets/images/filezilla_double_click_behavior.png)

???

* We also want to set the behavior of double clicking
* Easiest for our purposes to have a double click open a file rather than download it

---

## Let's test it out

* Log into AWS
* From your home directory (`cd ~`) do the following...

```
ubuntu@ip-172-30-0-221:~$ wget -O picture.jpg https://picsum.photos/400/?random
--2018-01-30 15:40:30--  https://picsum.photos/400/?random
Resolving picsum.photos (picsum.photos)... 104.37.178.1, 2610:1c8:c::1
Connecting to picsum.photos (picsum.photos)|104.37.178.1|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: /400/400/?image=360 [following]
--2018-01-30 15:40:30--  https://picsum.photos/400/400/?image=360
Reusing existing connection to picsum.photos:443.
HTTP request sent, awaiting response... 200 OK
Length: 20204 (20K) [image/jpeg]
Saving to: ‘picture.jpg’

picture.jpg          100%[====================>]  19.73K  --.-KB/s    in 0.001s

2018-01-30 15:40:30 (24.4 MB/s) - ‘picture.jpg’ saved [20204/20204]

ubuntu@ip-172-30-0-221:~$ ls
picture.jpg

```

???

The wget command should create an image file (picture.jpg) in your home directory.

---

class: middle

.left-column[
![:scale Before refreshing ]({{ site.baseurl }}/assets/images/filezilla_empty_directory.png)
]

--

.right-column[
![:scale After refreshing ]({{ site.baseurl }}/assets/images/filezilla_refrehsed_directory.png)

]

???
---

class: middle, center

![:scale A random picture ]({{ site.baseurl }}/assets/images/filezilla_random_picture.png)

???

You will get a different random picture

---

## Quitting

* For temporarily quitting AWS session...
  * Select your instance in the dashboard
  * Click on the "Actions" button along the top of the console.
  * Go Instance State -> Stop and click the blue button "Yes, Stop"
  * You will see the state change to "stoping" and then "stopped"
  * This is a safe state to leave your instance without getting charged for processing time
  * If you repeat the previous step, but click "Start", it will restart the instance, albeit with a different DNS address
* For permanently quitting AWS session...
  * If you instead click "Terminate", it will shut down the instance
  * All of your work will be deleted

???

* 'Control-b d' will detach tmux. If you're done with tmux, exit will get you out of tmux
* The exit command from the command line will log you out of AWS

---

class: middle, center

![Well done!]({{ site.baseurl }}/assets/images/good_job.gif)

---

## Exercises

* How can using an HPC facilitate reproducible research?
* What are the strengths and weaknesses of storing a project's analysis as an AMI?
* From your terminal, delete `picture.jpg`. Confirm that you can no longer see it in Filezilla
